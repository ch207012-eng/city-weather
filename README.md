# ğŸŒ¤ City Weather â€“ Real-Time Kafka Streaming Dashboard

A complete real-time streaming pipeline using **Apache Kafka**, **Python**, **Docker**, **OpenWeather API**, and **Dash/Plotly**.

This system fetches **live weather data** for 4 Minnesota cities, streams it into Kafka, consumes messages in real time, and displays them in a **live updating dashboard**.

---

## ğŸ“Œ Cities Streamed
- Saint Paul (MN)
- Duluth (MN)
- Saint Cloud (MN)
- Rochester (MN)

---

## ğŸ”§ Architecture Overview

```
OpenWeather API â†’ Producer (Python) â†’ Kafka Topic (city-weather) â†’ Consumer Thread â†’ Dash Web App â†’ Live Charts
```

### Components
- `producer/producer.py` â€” Fetches API weather data and streams JSON messages into Kafka every few seconds  
- `docker/docker-compose.yml` â€” Runs **Kafka + Zookeeper**  
- `consumer_dashboard/kafka_consumer_thread.py` â€” Background KafkaConsumer thread  
- `consumer_dashboard/app.py` â€” Dash app rendering real-time graphs  

---

## ğŸ“ Project Structure

```
city-weather/
â”‚
â”œâ”€â”€ producer/
â”‚   â”œâ”€â”€ producer.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ consumer_dashboard/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ kafka_consumer_thread.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## ğŸ§ª Environment Setup

### 1ï¸âƒ£ Create `.env` file

```
OPENWEATHER_API_KEY=YOUR_API_KEY_HERE
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
POLL_INTERVAL_SECONDS=300
```

---

## ğŸ³ 2ï¸âƒ£ Start Kafka & Zookeeper

```bash
cd /workspaces/city-weather
docker-compose -f docker/docker-compose.yml up -d
docker-compose -f docker/docker-compose.yml ps
```

Expected services:

```
docker-kafka-1       Up ... 0.0.0.0:9092->9092/tcp
docker-zookeeper-1   Up ... 0.0.0.0:2181->2181/tcp
```

---

## ğŸŒª 3ï¸âƒ£ Create Kafka Topic

```bash
KAFKA_CONTAINER=$(docker ps --filter "name=kafka" -q)

docker exec $KAFKA_CONTAINER kafka-topics --create   --topic city-weather   --bootstrap-server localhost:9092   --partitions 1   --replication-factor 1

docker exec $KAFKA_CONTAINER kafka-topics --list --bootstrap-server localhost:9092
```

---

## ğŸ 4ï¸âƒ£ Virtual Environment & Dependencies

```bash
python -m venv .venv
source .venv/bin/activate

pip install -r producer/requirements.txt
pip install -r consumer_dashboard/requirements.txt
```

---

## ğŸš€ 5ï¸âƒ£ Run Weather Producer (Terminal A)

```bash
cd producer
python producer.py
```

Expected:

```
ğŸŒ¤ Starting weather producer...
âœ… Sent to city-weather: {...}
â± Sleeping 300 seconds...
```

---

## ğŸ“Š 6ï¸âƒ£ Run Dash Consumer Dashboard (Terminal B)

```bash
cd consumer_dashboard
python app.py
```

Expected:

```
Attempting to connect to Kafka...
âœ… Kafka consumer connected!
Dash is running on http://0.0.0.0:8050
```

---

## ğŸŒ 7ï¸âƒ£ Open Dashboard (Port 8050)

In Codespaces â†’ **PORTS tab** â†’ click URL for **8050**:

```
https://xxxx-8050.app.github.dev
```

You will see real-time graphs updating automatically.

---

## ğŸ¥ Demo Requirements (Assignment)

### âœ” Kafka integration  
### âœ” Producer with real-time API data  
### âœ” Consumer + Dash UI  
### âœ” 5-minute PPT presentation (provided separately)  
### âœ” Upload code + PPT + demo video  

---

## ğŸ”® Future Improvements

- Add time-series database storage  
- Auto-scaling Kafka partitions  
- Add humidity, pressure, storms  
- Containerize everything in one Compose stack  

---

## ğŸ Summary

This project fully implements a **real-time Kafka streaming pipeline** with:
- Live OpenWeather API ingestion  
- Kafka topic streaming  
- Python consumer  
- Dash real-time visualization  
